# Section 6: Conclusion

## 6.1 Key Findings

This study demonstrates privacy governance-driven architectural design through a Cambodia elderly monitoring case study—or, to employ less grandiose language, it shows that starting with privacy principles and cost constraints rather than technical optimization yields different system architectures with implications for both governance implementation and market accessibility (whether this constitutes "demonstration" or merely "illustration" depends on how much weight one places on preliminary validation, a question this author declines to resolve definitively).

**Technical feasibility**: Edge-based pose estimation achieves 91.3% keypoint detection on 850nm NIR footage from affordable security cameras, validating 24/7 privacy-preserving monitoring capability without expensive visible-light or depth sensors. The finding matters less for advancing pose estimation algorithms (MediaPipe performance on NIR imagery hardly represents theoretical breakthrough) than for establishing deployment feasibility: affordable cameras can support pose-based fall detection, obviating need for cost-prohibitive sensor alternatives that exclude middle-income markets. The 91.3% detection rate comes with caveats (12.3% false negatives, 73.8-98.9% range across individual videos, testing on general populations rather than elderly subjects), but the central conclusion holds—NIR compatibility works adequately for this application.

**Cost-effectiveness**: Edge architecture reduces 3-year total cost by 61% compared to cloud-based fall detection alternatives ($672 vs. $1,719), expanding market reach to an estimated 216,000-324,000 elderly individuals in middle-income Cambodian households. The cost comparison reflects structural difference between one-time hardware investment and perpetual subscription fees, with edge system achieving breakeven at Month 13 and cost advantages compounding thereafter at $45/month avoided fees. Whether 61% cost reduction translates to substantially expanded adoption requires empirical validation beyond economic feasibility analysis, but the zero-subscription model eliminates recurring payment barriers that disproportionately affect households with variable income streams—a governance-relevant design choice even if we decline to label all cost optimization as "governance."

**Design trade-offs**: The selection of integrated YOLO+MediaPipe pipeline over simpler baseline MediaPipe-only approach—despite 2.3× slower processing speed—reflects safety-critical priority where accuracy trumps efficiency when both configurations exceed minimum requirements. The integrated pipeline's 5.7% higher keypoint detection and 22.2% better pose coverage provide reliability improvements that matter for applications where false negatives (missed fall detections) carry potentially fatal consequences. This represents governance-informed design trade-off, in a sense: prioritizing safety over computational efficiency embodies different values than commercial applications optimizing for cost reduction, though whether configuration selection constitutes meaningful "governance" or merely competent engineering remains—one suspects this has become a recurring theme—debatable.

**Governance-driven design**: Privacy governance principles informed architectural decisions from inception (edge processing, pose-only storage, immediate frame disposal) rather than being retrofitted post-deployment, demonstrating Cavoukian's Privacy by Design principles in healthcare AI context. The architecture enforces privacy through system constraints—facial recognition becomes impossible when no facial data exists, data breaches cannot expose video archives that were never created, cloud transmission risks vanish when processing never leaves local devices. This differs fundamentally from privacy-by-policy approaches that capture sensitive data and promise not to misuse it, a distinction that matters more in contexts where data protection regulation provides limited enforcement (Cambodia not being subject to GDPR or HIPAA, though stating geographical scope of Western privacy laws seems almost pedantically obvious).

## 6.2 Implications for Practice

### For Healthcare AI Developers

**NIR camera compatibility requires empirical validation** before deployment: the 73.8-98.9% detection range across the 20 test videos demonstrates that performance varies substantially by camera model, environmental conditions, and deployment specifics. Developers cannot assume that "pose estimation works" generalizes uniformly across camera types; camera-specific validation provides necessary deployment assurance. The validation need not be extensive—this study's 20-video testing took modest resources—but should sample the specific camera models and environmental conditions anticipated in target deployment.

**Integrated pipelines achieve real-time performance on standard hardware**, suggesting edge deployment feasibility though Jetson Orin Nano validation remains necessary for definitive claims. The 20.53 FPS throughput on consumer-grade GPU indicates that pose-based fall detection doesn't require specialized AI workstation hardware, which matters for cost-constrained deployments where every component expense affects market accessibility. However (and this caveat deserves emphasis), single-camera performance doesn't guarantee multi-camera deployment capability—4× simultaneous processing may reveal bottlenecks not apparent in single-stream testing.

**Privacy-by-design architecture is technically feasible** for elderly monitoring without sacrificing essential functionality. The pose-only storage approach eliminates facial recognition capability while maintaining adequate data for fall detection, demonstrating that privacy protections need not degrade application performance when embedded into architecture from inception. This suggests broader applicability: other healthcare AI applications might similarly achieve privacy through data minimization and edge processing rather than through encryption, access controls, or other post-collection protections that assume sensitive data capture is inevitable.

### For Policymakers

**Privacy-by-design architecture can yield economic co-benefits** beyond privacy protection alone: the 61% cost reduction emerges from edge processing that was motivated by privacy governance but that also eliminates cloud infrastructure expenses. This suggests that privacy and affordability need not trade off against each other—architectural choices that enforce privacy through data locality simultaneously reduce costs by eliminating subscription fees. Policymakers promoting healthcare AI adoption in middle-income markets might consider incentivizing edge-based privacy-first designs that expand accessibility while protecting sensitive health data.

**Zero-subscription models expand healthcare technology accessibility** in middle-income markets compared to recurring-fee alternatives, though this comes with qualification that "expand" means reaching 12-18% of elderly population rather than achieving universal access. The estimated 216,000-324,000 potential users represent meaningful public health impact if fall detection reduces injury-related mortality, but substantial population segments remain unreached. Low-income and rural elderly require different deployment approaches—potentially subsidized programs, community-based installations, or policy interventions beyond individual household purchases—that technology design alone cannot provide.

**Governance frameworks require implementation guidance** specific to developing country contexts rather than assuming Western regulatory models (GDPR, HIPAA) apply universally. When data protection regulations provide limited enforcement, privacy protection must emerge from system architecture rather than compliance mechanisms. This suggests need for governance frameworks that emphasize technical enforcement (architecture that makes privacy violations structurally impossible) over policy commitments (promises to protect data that require trusting institutional actors and enforcement agencies). Whether such frameworks prove politically feasible, given that they imply limitations on government data collection capabilities, represents separate question beyond this paper's scope.

---

**Closing thoughts**: This study demonstrates—or illustrates, or provides preliminary evidence for, depending on epistemic standards—that privacy governance principles can inform healthcare AI architecture in ways that expand market accessibility while protecting sensitive health data. The approach is not revolutionary (selecting appropriate hardware for deployment context, prioritizing privacy through data minimization, optimizing costs for target market all represent sound engineering practices), but framing these as governance-driven design choices rather than purely technical optimizations may prove useful for bridging the gap between abstract ethics guidelines and concrete implementation decisions.

Whether governance-driven design approaches generalize beyond this specific case study (Cambodian elderly monitoring using affordable NIR cameras and edge processors) remains empirically uncertain, requiring validation across different contexts, technologies, and applications. The author suspects that the core insight—starting with governance principles as design constraints rather than retrofitting compliance onto technically-optimized systems—applies broadly, but suspects and demonstrates remain distinct epistemic states that rigorous research should not conflate.

The validation provided here establishes technical feasibility of one governance-driven architectural approach, not comprehensive system validation or proof of broader applicability. Future work on fall detection accuracy, deployment reliability, user acceptance, and policy framework development will determine whether this preliminary study represents foundation for deployed systems that actually improve elderly safety or merely an academic exercise in demonstrating what might be possible if someone with more resources chose to pursue it (the author's hope leans toward the former but acknowledges the latter outcome occurs with depressing frequency in applied research).

---

**Word count**: ~1,380 words

**Style notes**: Maintained exhausted-academic voice through conclusion with appropriate hedging, acknowledgment of limitations, gesturing toward implications while retreating from overclaiming, and transparent admission about what was and wasn't demonstrated. The "closing thoughts" paragraph provides honest assessment of contribution while avoiding both false modesty and grandiose claims about impact.
